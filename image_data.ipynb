{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN0KUcziX4FqSlCvNUihqEM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeshdeepak/ImageCaptioning/blob/master/image_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z1JM3WFvtsY",
        "colab_type": "text"
      },
      "source": [
        "Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-2Jb0tQX12e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "# You'll generate plots of attention in order to see which parts of an image\n",
        "# our model focuses on during captioning\n",
        "import matplotlib.pyplot as plt\n",
        "# Scikit-learn includes many helpful utilities\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import pickle\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV6K4cE0zcsO",
        "colab_type": "text"
      },
      "source": [
        "Mount your google drive in Collab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8vWR24Wwdm9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "6b70d6b8-2224-48bd-c676-56a4af822a80"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YW6P-3fAznRu",
        "colab_type": "text"
      },
      "source": [
        "Download Annotations Folder to your google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfKcMF5eT9r6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download caption annotation files\n",
        "annotation_folder = '/annotations/'\n",
        "if not os.path.exists('/content/gdrive/My Drive/Colab Notebooks' + annotation_folder):\n",
        "  annotation_zip = tf.keras.utils.get_file('captions.zip',\n",
        "                                          cache_subdir='/content/gdrive/My Drive/Colab Notebooks',\n",
        "                                          origin = 'http://images.cocodataset.org/annotations/annotations_trainval2014.zip',\n",
        "                                          extract = True)\n",
        "  annotation_file = os.path.dirname(annotation_zip)+'/annotations/captions_train2014.json'\n",
        "  os.remove(annotation_zip)\n",
        "else:\n",
        "  annotation_file = '/content/gdrive/My Drive/Colab Notebooks/annotations/captions_train2014.json'\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhXbd4k9jfnM",
        "colab_type": "text"
      },
      "source": [
        "Retrieve all Image Ids for Vehicle Category from COCO Data Set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOusuMTqLsbZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "093fbe01-0132-4a66-9196-d4181b0c9857"
      },
      "source": [
        "from pycocotools.coco import COCO\n",
        "coco = COCO('/content/gdrive/My Drive/Colab Notebooks/annotations/instances_train2014.json')\n",
        "catIds = coco.getCatIds(catNms=['person'])\n",
        "# Get the corresponding image ids and images using loadImgs\n",
        "imgIds = coco.getImgIds(catIds=catIds)\n",
        "images = coco.loadImgs(imgIds)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=12.30s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1RR9Pqnj1K1",
        "colab_type": "text"
      },
      "source": [
        "Download all Images from Person Category to Seperate Folder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnXba_JBiW11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download image files\n",
        "image_folder = '/train2014'\n",
        "if not os.path.exists( '/content/gdrive/My Drive/Colab Notebooks'+ image_folder):\n",
        "   os.mkdir('/content/gdrive/My Drive/Colab Notebooks'+ image_folder)\n",
        "   images = images[0:1000]\n",
        "   image_id=[]\n",
        "   for img in images:\n",
        "     imageid=img['id']\n",
        "     url=img['coco_url']\n",
        "     filename=img['file_name']\n",
        "     image_id.append(imageid)\n",
        "\n",
        "     image_zip = tf.keras.utils.get_file(filename,\n",
        "                                      cache_subdir='/content/gdrive/My Drive/Colab Notebooks/train2014',\n",
        "                                      origin = url,\n",
        "                                      extract = True)\n",
        "     PATH = os.path.dirname(image_zip) +\"/\"\n",
        "      \n",
        "else:\n",
        "    images = images[0:1000]\n",
        "    image_id=[]\n",
        "    for img in images:\n",
        "      imageid=img['id']\n",
        "      url=img['coco_url']\n",
        "      filename=img['file_name']\n",
        "      image_id.append(imageid)\n",
        "      PATH = '/content/gdrive/My Drive/Colab Notebooks/train2014/'\n",
        " "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RcuSN1cke1C",
        "colab_type": "text"
      },
      "source": [
        "Store all the Labels and Image name in the form of Vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYGnLz6ecVCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(annotation_file, 'r') as f:\n",
        "    annotations = json.load(f)\n",
        "\n",
        "# Store captions and image names in vectors\n",
        "all_captions = []\n",
        "all_img_name_vector = []\n",
        "for img in image_id:\n",
        "  for annot in annotations['annotations']:\n",
        "    if img == annot['image_id']:\n",
        "       caption = '<start> ' + annot['caption'] + ' <end>'\n",
        "       #caption =  annot['caption'] \n",
        "       image_id = annot['image_id']\n",
        "       full_coco_image_path = PATH + 'COCO_train2014_' + '%012d.jpg' % (image_id)\n",
        "       all_img_name_vector.append(full_coco_image_path)\n",
        "       all_captions.append(caption)\n",
        "\n",
        "# Shuffle captions and image_names together\n",
        "# Set a random state\n",
        "img_name_train = all_img_name_vector[0:4499]\n",
        "cap_train = all_captions[0:4499]\n",
        "img_name_val = all_img_name_vector[4500:4999]\n",
        "cap_val = all_captions[4500:4999]\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8--xpqmwkp9E",
        "colab_type": "text"
      },
      "source": [
        "Store the Images and Captions to Image_Captioning.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF4P23eWLy28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "persondata = pd.DataFrame({ \"Image\" : all_img_name_vector,\"Captions\" : all_captions,})\n",
        "persondata=persondata.sort_values(by=['Image', 'Captions'])\n",
        "persondata.to_csv(\"/content/gdrive/My Drive/Colab Notebooks/Image_Captioning.csv\", index=False)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-ZGkPgWkz-3",
        "colab_type": "text"
      },
      "source": [
        "Split the Data into Training, Validation and Testing Data Set with 80%,10%,10% respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmHvV6ROLeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create training and validation sets using an 80-20 split\n",
        "\n",
        "#train_ratio = 0.80\n",
        "#validation_ratio = 0.10\n",
        "#img_name_train, img_name_val, cap_train, cap_val = train_test_split(img_name_vector,train_captions, test_size=1 - train_ratio)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNtbdR0RlAVL",
        "colab_type": "text"
      },
      "source": [
        "Load the Training, Testing and Validation Data Set in a csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffB0BFgMOTL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "traindata = pd.DataFrame({ \"Image\" : img_name_train,\"Captions\" : cap_train,})\n",
        "traindata=traindata.sort_values(by=['Image', 'Captions'])\n",
        "traindata.to_csv(\"/content/gdrive/My Drive/Colab Notebooks/Image_Captioning_train.csv\", index=False)\n",
        "valdata = pd.DataFrame({ \"Image\" : img_name_val,\"Captions\" : cap_val, })\n",
        "valdata=valdata.sort_values(by=['Image', 'Captions'])\n",
        "valdata.to_csv(\"/content/gdrive/My Drive/Colab Notebooks/Image_Captioning_validation.csv\", index=False)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfNqQ-bClQec",
        "colab_type": "text"
      },
      "source": [
        "Preprocess the images using InceptionV3\n",
        "Resizing the image to 299px by 299px\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I48yyBo-XVHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image(image_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, (299, 299))\n",
        "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "    return img, image_path\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ACtrPiHlclW",
        "colab_type": "text"
      },
      "source": [
        "Initialize InceptionV3 and load the pretrained Imagenet weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oish4GrzXb35",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "0f795895-0cff-47db-b7f4-bb6a96b39e33"
      },
      "source": [
        "image_model = tf.keras.applications.InceptionV3(include_top=False,\n",
        "                                                weights='imagenet')\n",
        "new_input = image_model.input\n",
        "hidden_layer = image_model.layers[-1].output\n",
        "\n",
        "image_features_extract_model = tf.keras.Model(new_input, hidden_layer)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQuP0J5cl4SO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q tqdm\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFaS8113lnS8",
        "colab_type": "text"
      },
      "source": [
        "Caching the features extracted from InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbcJ6cqmXum5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e236fa4-fe80-47ae-f9fd-d0dbe6bba46c"
      },
      "source": [
        "# Get unique images\n",
        "encode_train = sorted(set(img_name_train))\n",
        "# Feel free to change batch_size according to your system configuration\n",
        "image_dataset = tf.data.Dataset.from_tensor_slices(encode_train)\n",
        "image_dataset = image_dataset.map(\n",
        "  load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(16)\n",
        "for img, path in tqdm(image_dataset):\n",
        "\n",
        "  batch_features = image_features_extract_model(img)\n",
        "  batch_features = tf.reshape(batch_features,(batch_features.shape[0], -1, batch_features.shape[3]))\n",
        "  for bf, p in zip(batch_features, path):\n",
        "    path_of_feature = p.numpy().decode(\"utf-8\")\n",
        "    np.save(path_of_feature, bf.numpy())\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 57/57 [04:22<00:00,  4.60s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVvRLGkulu3e",
        "colab_type": "text"
      },
      "source": [
        "Preprocess and tokenize the captions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_ZvOHFGYZxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find the maximum length of any caption in our dataset\n",
        "def calc_max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB7dOPt7Yb4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Choose the top 5000 words from the vocabulary\n",
        "top_k = 5000\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=top_k,\n",
        "                                                  oov_token=\"<unk>\",\n",
        "                                                  filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
        "tokenizer.fit_on_texts(cap_train)\n",
        "train_seqs = tokenizer.texts_to_sequences(cap_train)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOIexxEjh_OM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(word):\n",
        "    # use real logic here\n",
        "    return word\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcPodLd-Ynh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.word_index['<pad>'] = 0\n",
        "tokenizer.index_word[0] = '<pad>'\n",
        "# Create the tokenized vectors\n",
        "train_seqs = tokenizer.texts_to_sequences(cap_train)\n",
        "# Pad each vector to the max_length of the captions\n",
        "# If you do not provide a max_length value, pad_sequences calculates it automatically\n",
        "cap_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, padding='post')\n",
        "# Calculates the max_length, which is used to store the attention weights\n",
        "max_length = calc_max_length(train_seqs)\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZi08ohqcrNK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42890da1-db61-4e79-98c6-8f1bb7a477fb"
      },
      "source": [
        "len(img_name_train), len(cap_train), len(img_name_val), len(cap_val)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4499, 4499, 499, 499)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIL9Uddvl4QQ",
        "colab_type": "text"
      },
      "source": [
        "Create a tf.data dataset for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRDa7v9NcxzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feel free to change these parameters according to your system's configuration\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "embedding_dim = 256\n",
        "units = 512\n",
        "vocab_size = top_k + 1\n",
        "num_steps = len(img_name_train) // BATCH_SIZE\n",
        "# Shape of the vector extracted from InceptionV3 is (64, 2048)\n",
        "# These two variables represent that vector shape\n",
        "features_shape = 2048\n",
        "attention_features_shape = 64\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKNI4tTzc0h6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the numpy files\n",
        "def map_func(img_name, cap):\n",
        "  img_tensor = np.load(img_name.decode('utf-8')+'.npy')\n",
        "  return img_tensor, cap\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUkcpzu-dAhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((img_name_train, cap_vector))\n",
        "\n",
        "# Use map to load the numpy files in parallel\n",
        "dataset = dataset.map(lambda item1, item2: tf.numpy_function(\n",
        "          map_func, [item1, item2], [tf.float32, tf.int32]),\n",
        "          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# Shuffle and batch\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo3noSbRmGhY",
        "colab_type": "text"
      },
      "source": [
        "In this example, you extract the features from the lower convolutional layer of InceptionV3 giving us a vector of shape (8, 8, 2048).\n",
        "You squash that to a shape of (64, 2048).\n",
        "This vector is then passed through the CNN Encoder (which consists of a single Fully connected layer).\n",
        "The RNN (here GRU) attends over the image to predict the next word.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X2pcnfCf190",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, features, hidden):\n",
        "    # features(CNN_encoder output) shape == (batch_size, 64, embedding_dim)\n",
        "\n",
        "    # hidden shape == (batch_size, hidden_size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden_size)\n",
        "    hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "\n",
        "    # score shape == (batch_size, 64, hidden_size)\n",
        "    score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
        "\n",
        "    # attention_weights shape == (batch_size, 64, 1)\n",
        "    # you get 1 at the last axis because you are applying score to self.V\n",
        "    attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * features\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sFdHPeIf6_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN_Encoder(tf.keras.Model):\n",
        "    # Since you have already extracted the features and dumped it using pickle\n",
        "    # This encoder passes those features through a Fully connected layer\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(CNN_Encoder, self).__init__()\n",
        "        # shape after fc == (batch_size, 64, embedding_dim)\n",
        "        self.fc = tf.keras.layers.Dense(embedding_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        return x\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cfz3bdIUgFZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN_Decoder(tf.keras.Model):\n",
        "  def __init__(self, embedding_dim, units, vocab_size):\n",
        "    super(RNN_Decoder, self).__init__()\n",
        "    self.units = units\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc1 = tf.keras.layers.Dense(self.units)\n",
        "    self.fc2 = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    self.attention = BahdanauAttention(self.units)\n",
        "\n",
        "  def call(self, x, features, hidden):\n",
        "    # defining attention as a separate model\n",
        "    context_vector, attention_weights = self.attention(features, hidden)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # shape == (batch_size, max_length, hidden_size)\n",
        "    x = self.fc1(output)\n",
        "\n",
        "    # x shape == (batch_size * max_length, hidden_size)\n",
        "    x = tf.reshape(x, (-1, x.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size * max_length, vocab)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x, state, attention_weights\n",
        "\n",
        "  def reset_state(self, batch_size):\n",
        "    return tf.zeros((batch_size, self.units))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHmYAdumgNLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = CNN_Encoder(embedding_dim)\n",
        "decoder = RNN_Decoder(embedding_dim, units, vocab_size)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu3DTQfXgQjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOITQMy3gUn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"./checkpoints/train\"\n",
        "ckpt = tf.train.Checkpoint(encoder=encoder,\n",
        "                           decoder=decoder,\n",
        "                           optimizer = optimizer)\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6x0ydGGgYtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_epoch = 0\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n",
        "  # restoring the latest checkpoint in checkpoint_path\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHo9p0a0geyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adding this in a separate cell because if you run the training cell\n",
        "# many times, the loss_plot array will be reset\n",
        "loss_plot = []\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1ka21TUgiUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(img_tensor, target):\n",
        "  loss = 0\n",
        "\n",
        "  # initializing the hidden state for each batch\n",
        "  # because the captions are not related from image to image\n",
        "  hidden = decoder.reset_state(batch_size=target.shape[0])\n",
        "\n",
        "  dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * target.shape[0], 1)\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "      features = encoder(img_tensor)\n",
        "\n",
        "      for i in range(1, target.shape[1]):\n",
        "          # passing the features through the decoder\n",
        "          predictions, hidden, _ = decoder(dec_input, features, hidden)\n",
        "\n",
        "          loss += loss_function(target[:, i], predictions)\n",
        "\n",
        "          # using teacher forcing\n",
        "          dec_input = tf.expand_dims(target[:, i], 1)\n",
        "\n",
        "  total_loss = (loss / int(target.shape[1]))\n",
        "\n",
        "  trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, trainable_variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "\n",
        "  return loss, total_loss\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usJ5XcF6goB6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1a1fd9cd-9e86-4450-8efb-76d0cbea82a3"
      },
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "for epoch in range(start_epoch, EPOCHS):\n",
        "    start = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (img_tensor, target)) in enumerate(dataset):\n",
        "        batch_loss, t_loss = train_step(img_tensor, target)\n",
        "        total_loss += t_loss\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print ('Epoch {} Batch {} Loss {:.4f}'.format(\n",
        "              epoch + 1, batch, batch_loss.numpy() / int(target.shape[1])))\n",
        "    # storing the epoch end loss value to plot later\n",
        "    loss_plot.append(total_loss / num_steps)\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "      ckpt_manager.save()\n",
        "\n",
        "    print ('Epoch {} Loss {:.6f}'.format(epoch + 1,\n",
        "                                         total_loss/num_steps))\n",
        "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.1160\n",
            "Epoch 1 Loss 1.423041\n",
            "Time taken for 1 epoch 71.78651213645935 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.2652\n",
            "Epoch 2 Loss 1.186483\n",
            "Time taken for 1 epoch 14.606194972991943 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.0679\n",
            "Epoch 3 Loss 1.038776\n",
            "Time taken for 1 epoch 13.650702238082886 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.0210\n",
            "Epoch 4 Loss 0.939605\n",
            "Time taken for 1 epoch 14.023812532424927 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.9549\n",
            "Epoch 5 Loss 0.854218\n",
            "Time taken for 1 epoch 13.47411036491394 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.7864\n",
            "Epoch 6 Loss 0.788631\n",
            "Time taken for 1 epoch 14.31080150604248 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.7316\n",
            "Epoch 7 Loss 0.729473\n",
            "Time taken for 1 epoch 14.04964017868042 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.6441\n",
            "Epoch 8 Loss 0.679988\n",
            "Time taken for 1 epoch 13.888096570968628 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.6549\n",
            "Epoch 9 Loss 0.635566\n",
            "Time taken for 1 epoch 14.472047328948975 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.5874\n",
            "Epoch 10 Loss 0.591295\n",
            "Time taken for 1 epoch 14.173993587493896 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.5760\n",
            "Epoch 11 Loss 0.555604\n",
            "Time taken for 1 epoch 14.341102123260498 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.5175\n",
            "Epoch 12 Loss 0.522082\n",
            "Time taken for 1 epoch 13.421435594558716 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.5027\n",
            "Epoch 13 Loss 0.492379\n",
            "Time taken for 1 epoch 13.476459980010986 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.4602\n",
            "Epoch 14 Loss 0.467614\n",
            "Time taken for 1 epoch 13.61368703842163 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.4204\n",
            "Epoch 15 Loss 0.441515\n",
            "Time taken for 1 epoch 13.907494306564331 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.3856\n",
            "Epoch 16 Loss 0.416321\n",
            "Time taken for 1 epoch 14.044365882873535 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.3929\n",
            "Epoch 17 Loss 0.391352\n",
            "Time taken for 1 epoch 13.768340826034546 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.3816\n",
            "Epoch 18 Loss 0.373162\n",
            "Time taken for 1 epoch 13.943637132644653 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.3424\n",
            "Epoch 19 Loss 0.345943\n",
            "Time taken for 1 epoch 13.873003244400024 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.3314\n",
            "Epoch 20 Loss 0.329535\n",
            "Time taken for 1 epoch 13.825879335403442 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SctC6RRYJTot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b7c105b6-fb99-4125-b821-88f7027e3783"
      },
      "source": [
        "plt.plot(loss_plot)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Plot')\n",
        "plt.show()\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6fLRfjimcDX",
        "colab_type": "text"
      },
      "source": [
        "The evaluate function is similar to the training loop, except you don't use teacher forcing here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
        "Stop predicting when the model predicts the end token.\n",
        "And store the attention weights for every time step.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-12PVUjJUtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(image):\n",
        "    attention_plot = np.zeros((max_length, attention_features_shape))\n",
        "    \n",
        "    hidden = decoder.reset_state(batch_size=1)\n",
        "\n",
        "    temp_input = tf.expand_dims(load_image(image)[0], 0)\n",
        "    img_tensor_val = image_features_extract_model(temp_input)\n",
        "    img_tensor_val = tf.reshape(img_tensor_val, (img_tensor_val.shape[0], -1, img_tensor_val.shape[3]))\n",
        "\n",
        "    features = encoder(img_tensor_val)\n",
        "\n",
        "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
        "    result = []\n",
        "\n",
        "    for i in range(max_length):\n",
        "        predictions, hidden, attention_weights = decoder(dec_input, features, hidden)\n",
        "\n",
        "        attention_plot[i] = tf.reshape(attention_weights, (-1, )).numpy()\n",
        "\n",
        "        predicted_id = tf.random.categorical(predictions, 1)[0][0].numpy()\n",
        "        result.append(tokenizer.index_word[predicted_id])\n",
        "\n",
        "        if tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, attention_plot\n",
        "\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    attention_plot = attention_plot[:len(result), :]\n",
        "    return result, attention_plot\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZdkKihnJlab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_attention(image, result, attention_plot):\n",
        "    temp_image = np.array(Image.open(image))\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "    len_result = len(result)\n",
        "    for l in range(len_result):\n",
        "        temp_att = np.resize(attention_plot[l], (8, 8))\n",
        "        ax = fig.add_subplot(len_result//2, len_result//2, l+1)\n",
        "        ax.set_title(result[l])\n",
        "        img = ax.imshow(temp_image)\n",
        "        ax.imshow(temp_att, cmap='gray', alpha=0.6, extent=img.get_extent())\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVNzqu-BQEp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.fit_on_texts(cap_val)\n",
        "train_seqs = tokenizer.texts_to_sequences(cap_val)\n",
        "tokenizer.word_index['<pad>'] = 0\n",
        "tokenizer.index_word[0] = '<pad>'\n",
        "# Create the tokenized vectors\n",
        "test_seqs = tokenizer.texts_to_sequences(cap_val)\n",
        "# Pad each vector to the max_length of the captions\n",
        "# If you do not provide a max_length value, pad_sequences calculates it automatically\n",
        "cap_test_vector = tf.keras.preprocessing.sequence.pad_sequences(test_seqs, padding='post')\n",
        "# Calculates the max_length, which is used to store the attention weights\n",
        "max_length = calc_max_length(test_seqs )\n",
        "\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PU-0LluAnmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_index_positions(list_of_elems, element):\n",
        "    index_pos_list = []\n",
        "    index_pos = 0\n",
        "    while True:\n",
        "        try:\n",
        "            # Search for item in list from indexPos to the end of list\n",
        "            index_pos = list_of_elems.index(element, index_pos)\n",
        "            # Add the index position in list\n",
        "            index_pos_list.append(index_pos)\n",
        "            index_pos += 1\n",
        "        except ValueError as e:\n",
        "            break\n",
        "    return index_pos_list\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls2uyYHb15P6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9efa82b9-56e9-487c-ee2f-90b59f466649"
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "valimage_url=[]\n",
        "valreal_cap=[]\n",
        "valpred_cap=[]\n",
        "val_accuracy=[]\n",
        "with open('/content/gdrive/My Drive/Colab Notebooks/pred_val_results.txt', 'w') as writefile:\n",
        "\n",
        " for name in np.unique(img_name_val):\n",
        "  imageurl=\"http://images.cocodataset.org/train2014/\"+os.path.basename(name)\n",
        "  print(imageurl)\n",
        "  image = name\n",
        "  result, attention_plot = evaluate(image) \n",
        "  final_result_1=' '.join(result)\n",
        "  final_result=[final_result_1]\n",
        "  predicted_caption = [tokenize(word) for sentence in final_result for word in sentence.split()]\n",
        "  predicted_caption=predicted_caption\n",
        "  for val_img_name in img_name_val:\n",
        "    if name == val_img_name:\n",
        "      list_real_captions_1=[]\n",
        "      rc=[]\n",
        "      rid= get_index_positions(img_name_val,val_img_name)\n",
        "      for rid in rid:\n",
        "         real_caption = ' '.join([tokenizer.index_word[i] for i in cap_test_vector[rid] if i not in [0]])\n",
        "         real_caption_1=[real_caption]\n",
        "         real_caption_1 = [tokenize(word) for sentence in real_caption_1 for word in sentence.split()]\n",
        "         final_result=[final_result_1]\n",
        "         length=len(real_caption_1)\n",
        "         del real_caption_1[length-1] \n",
        "         del real_caption_1[0] \n",
        "         length=len(predicted_caption)\n",
        "         #del predicted_caption[length-1] \n",
        "         real_captions=real_caption_1\n",
        "         list_real_captions=real_captions\n",
        "         list_real_captions_1.append(list_real_captions)\n",
        "         rc.append(real_caption  ) \n",
        "  final_rc = '\\n'.join(rc)\n",
        "       \n",
        "  print ('Real Caption:', final_rc)\n",
        "  print ('Predicted Caption:', final_result_1)\n",
        "  #print(list_real_captions_1)\n",
        "  #print(predicted_caption)\n",
        "  accuracy=sentence_bleu(list_real_captions_1, predicted_caption,weights=(0.33,0.33,0.33,0))\n",
        "  print('BLEU Score: %f'  % sentence_bleu(list_real_captions_1, predicted_caption,weights=(0.33,0.33,0.33,0)))\n",
        "  print(\"\\n\")\n",
        "  valimage_url.append(imageurl) \n",
        "  valreal_cap.append(rc) \n",
        "  valpred_cap.append(final_result_1  ) \n",
        "  accuracy=str(accuracy)\n",
        "  val_accuracy.append(accuracy)\n",
        "  writefile.write(imageurl )\n",
        "  writefile.write(\"\\n\")\n",
        "  writefile.write(\"Real Captions:\")\n",
        "  writefile.write(\"\\n\")\n",
        "  writefile.write(final_rc )\n",
        "  writefile.write(\"Predicted Caption: \" )\n",
        "  writefile.write(\"\\n\")\n",
        "  writefile.write(final_result_1)\n",
        "  writefile.write(\"\\n\")\n",
        "  writefile.write(\"Bleu Score: \" )\n",
        "  writefile.write(accuracy )\n",
        "  writefile.write(\"\\n\")\n",
        "  writefile.write(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        " \n",
        "\n",
        "\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002415.jpg\n",
            "Real Caption: <start> some people and a brown and white animal and grass <end>\n",
            "<start> a group of men trying to move an animal <end>\n",
            "<start> an animal sits on the grass as several people watch <end>\n",
            "<start> a yak being pulled by the towns people in foreign land <end>\n",
            "<start> a group of men pull a bovine by its horns <end>\n",
            "Predicted Caption: a man ted with a glass <end>\n",
            "BLEU Score: 0.497019\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002444.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Real Caption: <start> a large horse is attached to a carriage <end>\n",
            "<start> a horse pulling a cart near some houses <end>\n",
            "<start> a team of clydsdales hitched to a carriage in front of a building <end>\n",
            "<start> two horses strapped to the front of a carriage stop in front of a wooden building <end>\n",
            "<start> two large draught horses harnessed in to a carriage <end>\n",
            "Predicted Caption: a bicycle scooter cabinets <end>\n",
            "BLEU Score: 0.322673\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002445.jpg\n",
            "Real Caption: <start> a baseball player swinging a baseball bat over home plate <end>\n",
            "<start> baseball player preparing to swing his bat at the plate <end>\n",
            "<start> a baseball game in progress with the pitch in the middle of a swing <end>\n",
            "<start> a batter swings at the ball as the catcher and umpire watch <end>\n",
            "<start> a person that is swinging a bat in a baseball game <end>\n",
            "Predicted Caption: a air her two a ski <end>\n",
            "BLEU Score: 0.430855\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002446.jpg\n",
            "Real Caption: <start> a young boy in a soccer uniform kicking a ball <end>\n",
            "<start> a little boy kicking a soccer ball on a soccer field <end>\n",
            "<start> a young boy kicking a soccer ball on a green field <end>\n",
            "<start> a boy putting his leg back to kick a soccer ball <end>\n",
            "<start> a boy in a soccer game about to kick the ball <end>\n",
            "Predicted Caption: little swinging white on street park of someone field being a someone <end>\n",
            "BLEU Score: 0.677764\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002459.jpg\n",
            "Real Caption: <start> a woman sitting in front of a laptop computer <end>\n",
            "<start> a woman looking at a laptop computer <end>\n",
            "<start> a woman is at work on her computer <end>\n",
            "<start> the young woman is looking at her lap top <end>\n",
            "<start> a woman looking at a laptop with the sun cause a glare on the screen <end>\n",
            "Predicted Caption: a man pedestrians a one <end>\n",
            "BLEU Score: 0.589071\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002466.jpg\n",
            "Real Caption: <start> woman at an outdoor dining room table looking at food <end>\n",
            "<start> a woman looking at a tray of food on the table <end>\n",
            "<start> a woman sitting at a table looking over a plate of food <end>\n",
            "<start> a woman looking at a platter laden with food <end>\n",
            "<start> a person that is looking at some food on the table <end>\n",
            "Predicted Caption: a man two near of very <end>\n",
            "BLEU Score: 0.497019\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002470.jpg\n",
            "Real Caption: <start> snowboarder on large snow covered slope in alpine area <end>\n",
            "<start> a man riding a snowboard down a snow covered slope <end>\n",
            "<start> a person riding a snowboard down a slope with other people behind him <end>\n",
            "<start> a man on a snow board cutting up some snow <end>\n",
            "<start> a person is coming down a hill on a snowboard <end>\n",
            "Predicted Caption: a man and a skate of a airplane with restaurant <end>\n",
            "BLEU Score: 0.360579\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002498.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Real Caption: <start> a group of kids play frisbee in a muddy field while it rains <end>\n",
            "<start> a small group of people are playing frisbee in the mud <end>\n",
            "<start> a group of four people play frisbee on the beach <end>\n",
            "<start> a group of people jump to catch a frisbee on the beach <end>\n",
            "<start> a group of people are outdoors playing with a frisbee in the rain <end>\n",
            "Predicted Caption: a his of people board at a child of people men resting the frisbee and a his of people an in skateboard of city shown\n",
            "BLEU Score: 0.230193\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002536.jpg\n",
            "Real Caption: <start> several people on surfboards waiting for a good wave <end>\n",
            "<start> a group of surfers are waiting on the water to catch the next wave <end>\n",
            "<start> bunch of people out in the water on surfboards waiting for a wave <end>\n",
            "<start> a group of people are in the ocean on surfboards <end>\n",
            "<start> surfers paddling into the ocean on their boards <end>\n",
            "Predicted Caption: a man that is person in a rear <end>\n",
            "BLEU Score: 0.608751\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002543.jpg\n",
            "Real Caption: <start> two children lie in bed under a blanket <end>\n",
            "<start> two children are lying in a bed under an afghan <end>\n",
            "<start> amazing picture of various individuals having a not too bad time \n",
            " <end>\n",
            "<start> a little boy and girl laying down on a bed <end>\n",
            "<start> two children are laying on a bed looking frightened <end>\n",
            "Predicted Caption: a man family a bat <end>\n",
            "BLEU Score: 0.498638\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002555.jpg\n",
            "Real Caption: <start> a person doing a trick on a surfboard in the ocean <end>\n",
            "<start> a surfer in the ocean surfing over a wave <end>\n",
            "<start> black and white photograph of a person riding on a wave <end>\n",
            "<start> a surfer riding the waves of the ocean <end>\n",
            "<start> black and white image of a surfer riding a wave <end>\n",
            "Predicted Caption: a man buildings on a surfboard buildings in the wearing <end>\n",
            "BLEU Score: 0.266490\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002560.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Real Caption: <start> a tennis player getting ready to serve the ball <end>\n",
            "<start> a woman taking a swing at a tennis ball <end>\n",
            "<start> a girl dressed all in orange hitting a tennis ball <end>\n",
            "<start> a woman swinging a tennis racquet at a tennis ball <end>\n",
            "<start> young woman in orange dress about to serve in tennis game on blue court with green sides <end>\n",
            "Predicted Caption: a man video a tennis about <end>\n",
            "BLEU Score: 0.345878\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002563.jpg\n",
            "Real Caption: <start> people are standing in a field with kites flying above <end>\n",
            "<start> a person playing with a kite in the middle of a field <end>\n",
            "<start> a group of people flying kites in a field <end>\n",
            "<start> people flying kites in an open field on a sunny day <end>\n",
            "<start> people in a large grassy area flying kites up into the sky <end>\n",
            "Predicted Caption: frisbee three of a dryer <end>\n",
            "BLEU Score: 0.248166\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002567.jpg\n",
            "Real Caption: <start> a woman is throwing an orange frisbee to a kid <end>\n",
            "<start> two people play frisbee in a school gym <end>\n",
            "<start> a girl is throwing a frisbee to a boy while in a gym <end>\n",
            "<start> young adults playing with flying disc at indoor gymnasium <end>\n",
            "<start> two people playing frisbee together in a building <end>\n",
            "Predicted Caption: a frisbee and a bicycle and outside of a man in a propeller around <end>\n",
            "BLEU Score: 0.388864\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002575.jpg\n",
            "Real Caption: <start> a woman standing on a tennis court holding a racquet <end>\n",
            "<start> a woman playing tennis on a tennis court <end>\n",
            "<start> a female tennis player hitting the ball with her racket <end>\n",
            "<start> a female professional tennis player returning a ball <end>\n",
            "<start> a woman hitting a tennis ball on the court <end>\n",
            "Predicted Caption: a man is white tennis <end>\n",
            "BLEU Score: 0.498638\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002583.jpg\n",
            "Real Caption: <start> a boy on a snow board poses for the camera <end>\n",
            "<start> a man on a snowboard on top of a large snow bank <end>\n",
            "<start> a man standing on a snowboard in the snow <end>\n",
            "<start> this is a photo of a man snow boarding <end>\n",
            "<start> a man riding a snow board down a snow covered slope <end>\n",
            "Predicted Caption: a sitting an in street road snow toppings <end>\n",
            "BLEU Score: 0.695905\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002585.jpg\n",
            "Real Caption: <start> a woman standing in front of a kitchen counter <end>\n",
            "<start> a woman cooking dinner in her kitchen while drinking a soda <end>\n",
            "<start> a woman that is standing in a kitchen near a counter <end>\n",
            "<start> a woman with eyeglasses in a kitchen with bowls spoon and glasses <end>\n",
            "<start> a woman with glasses in her kitchen preparing food <end>\n",
            "Predicted Caption: a man elephants motorcycle in a kitchen who racket of motorcycle at shaved food in a kitchen <end>\n",
            "BLEU Score: 0.144735\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002602.jpg\n",
            "Real Caption: <start> a young girl stands on her bunk bed holding a paper <end>\n",
            "<start> a girl standing on a bed holding up a sign <end>\n",
            "<start> a girl is standing on a bed surrounded by books holding a piece of paper <end>\n",
            "<start> the girl is standing on her bed holding up her artwork <end>\n",
            "<start> a girl holding up a book with a pile of books at her feet <end>\n",
            "Predicted Caption: a man an in a surface <end>\n",
            "BLEU Score: 0.430855\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002614.jpg\n",
            "Real Caption: <start> a couple of men playing a game of frisbee <end>\n",
            "<start> a group of people playing frisbee in the water near a beach <end>\n",
            "<start> two people playing with frisbees near the water <end>\n",
            "<start> a big crowded beach with some guys playing with a disc <end>\n",
            "<start> two men play in the mud as others stand in the background <end>\n",
            "Predicted Caption: a truck with a small blue with a man and older man two a small blue two a small off baby a pair of a\n",
            "BLEU Score: 0.218776\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002639.jpg\n",
            "Real Caption: <start> two buses driving down a curvy street next to a building <end>\n",
            "<start> two double high buses that are sitting in the street <end>\n",
            "<start> a couple of city buses ride on a city street <end>\n",
            "<start> a yellow bus and a blue bus drive next to each other in the city <end>\n",
            "<start> yellow and blue double decker buses traveling side by side <end>\n",
            "Predicted Caption: a looks waiting girl <end>\n",
            "BLEU Score: 0.216294\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002644.jpg\n",
            "Real Caption: <start> there is a sightseeing bus on the side of the road <end>\n",
            "<start> a red double decker bus driving through the streets of london <end>\n",
            "<start> people sit on the roof of a tour bus <end>\n",
            "<start> the city has a large packed tour bus driving down the road <end>\n",
            "<start> a double decker sightseeing bus drives down a london street <end>\n",
            "Predicted Caption: a some girl court stopped in skateboard of a glasses building <end>\n",
            "BLEU Score: 0.286854\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002658.jpg\n",
            "Real Caption: <start> a group of men standing next to each other dancing <end>\n",
            "<start> a group of young men standing on a basketball court <end>\n",
            "<start> children prepare for physical activity in a gymnasium <end>\n",
            "<start> a man with jacket and tie seems out of place among sweaty t shirt clad men on a gym floor <end>\n",
            "<start> a man in a suit stands in the middle of a group of people <end>\n",
            "Predicted Caption: a his of people white with street off <end>\n",
            "BLEU Score: 0.385265\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000002664.jpg\n",
            "Real Caption: <start> a reclining lounge chair mounted on a bicycle <end>\n",
            "<start> a bike with a lawn chair attached to part of it <end>\n",
            "<start> the beach chair is attached to the bike <end>\n",
            "<start> lots of bicycles and people with a chase lounge on one <end>\n",
            "<start> bike made with lounge chair on top for passenger to ride in <end>\n",
            "Predicted Caption: a man that is tree and throwing <end>\n",
            "BLEU Score: 0.723486\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133482.jpg\n",
            "Real Caption: <start> the man is riding a horse while holding a flag <end>\n",
            "Predicted Caption: a man in a phone bed in a phone others children with a upright <end>\n",
            "BLEU Score: 0.587949\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133486.jpg\n",
            "Real Caption: <start> a person in a kitchen preparing food on a table <end>\n",
            "<start> a man preparing food for a meal inside of a kitchen <end>\n",
            "<start> this person is preparing a meal in the kitchen <end>\n",
            "<start> a man fixing a bowl of food at a counter <end>\n",
            "<start> a person in an apron standing over a small metal bowl on counter in a kitchen <end>\n",
            "Predicted Caption: a sitting in a basketball of motorcycle basketball motorcycle <end>\n",
            "BLEU Score: 0.357915\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133490.jpg\n",
            "Real Caption: <start> a man in red shirt flying a kite in a park <end>\n",
            "<start> a kid watching a kite hit the ground in a park <end>\n",
            "<start> a man in a park trying to get his kite to fly <end>\n",
            "<start> a man a raising his arms as a kite crashes in a field <end>\n",
            "<start> a man with a kite holds his hands in the air <end>\n",
            "Predicted Caption: a sitting an in a park <end>\n",
            "BLEU Score: 0.192096\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133492.jpg\n",
            "Real Caption: <start> a small group of guys taking a photo in the park with some frisbees <end>\n",
            "<start> several people standing together in a grassy field <end>\n",
            "<start> a group of people posing for a picture with frisbee's <end>\n",
            "<start> a group of people who play frisbee pose together <end>\n",
            "<start> a man and his team are in a soccer field <end>\n",
            "Predicted Caption: the small beach and a decorated his of by that are pitch flying a some umbrella and a three of a controllers <end>\n",
            "BLEU Score: 0.733719\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133505.jpg\n",
            "Real Caption: <start> someone on their yellow motorcycle dressed in all yellow <end>\n",
            "<start> a man runs after a guy on a motorcycle <end>\n",
            "<start> a person on a motorcycle on a track near another person <end>\n",
            "<start> there is a man on a motorcycle and a man running behind him <end>\n",
            "<start> a person riding on a motor bike on a road <end>\n",
            "Predicted Caption: a talking dark held and room lot a room boards a room butter a room on a tie scooter umbrellas on a picture <end>\n",
            "BLEU Score: 0.282677\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133508.jpg\n",
            "Real Caption: <start> a young man in a wet suite is giving the thumbs up <end>\n",
            "<start> some guy standing on a beach with a surf board <end>\n",
            "<start> a man carrying a yellow surfboard on top of a beach <end>\n",
            "<start> the man is holding a surf board next to the ocean <end>\n",
            "<start> a man poses for the camera while holding his yellow surfboard <end>\n",
            "Predicted Caption: a county racket street kites road other at a kites other <end>\n",
            "BLEU Score: 0.553618\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133510.jpg\n",
            "Real Caption: <start> a baseball player holding a bat while standing next to home plate <end>\n",
            "<start> a pitcher prepares to throw the ball to the hitter <end>\n",
            "<start> a baseball player is holding a bat at a game <end>\n",
            "<start> a baseball player is at bat waiting for the pitch <end>\n",
            "<start> a boston red sox pitcher stands holding the ball in his glove at his waist prepares to pitch to an oakland a's batter <end>\n",
            "Predicted Caption: a skateboarder of by next to a walks dress park with street hand and a small by on the sidewalk <end>\n",
            "BLEU Score: 0.223747\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133532.jpg\n",
            "Real Caption: <start> three people skiing together in a line down a hill <end>\n",
            "<start> three people on skis holding onto a tow line <end>\n",
            "<start> three skiers holding a rope in the snow <end>\n",
            "<start> three people climbing up a ski slope line <end>\n",
            "<start> three people holding onto a line while wearing skis <end>\n",
            "Predicted Caption: a man is an in the table <end>\n",
            "BLEU Score: 0.380669\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133540.jpg\n",
            "Real Caption: <start> a heard of goats are shown close together <end>\n",
            "<start> a shepherd with a group of goats with some of them marked red <end>\n",
            "<start> a man is standing with a flock of sheep <end>\n",
            "<start> a herd of horned animals on a field <end>\n",
            "<start> a person standing behind a large herd of rams <end>\n",
            "Predicted Caption: standing staring of hand boogie <end>\n",
            "BLEU Score: 0.498638\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133543.jpg\n",
            "Real Caption: <start> a woman standing and using a cell phone <end>\n",
            "<start> a young girl uses a cell phone <end>\n",
            "<start> a women that is standing up holding a cell phone <end>\n",
            "<start> a girl in a pink shirt is looking at a cell phone <end>\n",
            "<start> a girl is standing and using a cellphone <end>\n",
            "Predicted Caption: a he group a seen to street attempting scene two a it board light a cake <end>\n",
            "BLEU Score: 0.564159\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133549.jpg\n",
            "Real Caption: <start> a beach area with tent and umbrellas and people in water <end>\n",
            "<start> a beach shore with a shallow strip of water passing through it <end>\n",
            "<start> tent and umbrellas on the beach while people play in the ocean <end>\n",
            "<start> a landscape shot of a beach with a few people sitting using umbrellas <end>\n",
            "<start> some one camping on a beach during the day <end>\n",
            "Predicted Caption: a sitting two a frisbee and a large tie and a passengers cow beer intersection working racket at a frisbee umbrella is on a boy\n",
            "BLEU Score: 0.230193\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133576.jpg\n",
            "Real Caption: <start> a person lying on a bed with white sheets <end>\n",
            "<start> middle aged man laying shirtless across a bed <end>\n",
            "<start> a shirtless man laying across a bed <end>\n",
            "<start> there is a man laying on a bed and smiling <end>\n",
            "<start> a man without a shirt on laying across a bed <end>\n",
            "Predicted Caption: the blue person down in the few <end>\n",
            "BLEU Score: 0.503478\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133580.jpg\n",
            "Real Caption: <start> a young boy holding a baseball bat near a batting cage <end>\n",
            "<start> a man and a boy playing baseball on the field <end>\n",
            "<start> a man is pitching a ball to a kid <end>\n",
            "<start> small child holding a baseball bat with man throwing ball <end>\n",
            "<start> a man pitching a ball to a child holding a baseball bat <end>\n",
            "Predicted Caption: a man in standing tennis <end>\n",
            "BLEU Score: 0.248166\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133615.jpg\n",
            "Real Caption: <start> a young girl stands on a court holding a tennis racket <end>\n",
            "<start> a cute little girl holding a tennis racket <end>\n",
            "<start> a little girl in blue dress on tennis court holding raquet <end>\n",
            "<start> a small child is holding a tennis racket on the court <end>\n",
            "<start> small child in blue outfit holding up a tennis racket <end>\n",
            "Predicted Caption: a tennis her is returns down at standing hold crossing at the field <end>\n",
            "BLEU Score: 0.283698\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133627.jpg\n",
            "Real Caption: <start> a woman using a smart phone while sitting down <end>\n",
            "<start> a woman smiles and takes a picture of herself <end>\n",
            "<start> a woman laughing while checking out her cell phone <end>\n",
            "<start> a series of images showing a woman using a cell phone <end>\n",
            "<start> a collage of three photos with a woman holding a cell phone <end>\n",
            "Predicted Caption: a young laying black a three <end>\n",
            "BLEU Score: 0.568177\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133634.jpg\n",
            "Real Caption: <start> a mother and daughter smile as they eat their meal <end>\n",
            "<start> a girl is smiling with a woman while a plate of french toast and eggs is on a table <end>\n",
            "<start> a woman and a girl eat breakfast at a restaurant <end>\n",
            "<start> there is a woman and a girl eating breakfast foods <end>\n",
            "<start> a couple of women sitting in front of a table of food <end>\n",
            "Predicted Caption: a child of kitchen snow elephants a drinking <end>\n",
            "BLEU Score: 0.622723\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133641.jpg\n",
            "Real Caption: <start> a teddy bear is sitting in a chair near a fountain <end>\n",
            "<start> a teddy bear sitting in a stroller outside of a fountain <end>\n",
            "<start> a teddy bear in a baby stroller sitting beside a body of water with a fountain <end>\n",
            "<start> teddy bear sitting in stroller next to a water fountain <end>\n",
            "<start> a teddy bear sitting in a stroller next to a fountain <end>\n",
            "Predicted Caption: a counter of a frisbee other <end>\n",
            "BLEU Score: 0.272679\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133650.jpg\n",
            "Real Caption: <start> people standing at table cutting an american flag cake <end>\n",
            "<start> four people are standing by a cake shaped like an american flag <end>\n",
            "<start> a group of people that are about to cut a cake <end>\n",
            "<start> four adults admiring a large and colorful sheet cake <end>\n",
            "<start> two men and two women cutting a cake decorated like a flag <end>\n",
            "Predicted Caption: a man and a his of people area flying front slope <end>\n",
            "BLEU Score: 0.339524\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133654.jpg\n",
            "Real Caption: <start> a group of people posting for a picture on a tennis court <end>\n",
            "<start> two men and two women stand in front of a tennis net <end>\n",
            "<start> an old photo of some people standing next to a tennis court net <end>\n",
            "<start> a group of people standing on a tennis court <end>\n",
            "<start> vintage photos of couples posing on a tennis court <end>\n",
            "Predicted Caption: a man on a bottle umbrella and outside <end>\n",
            "BLEU Score: 0.385265\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133660.jpg\n",
            "Real Caption: <start> a man is on a beach preparing to catch a frisbee <end>\n",
            "<start> a man on a beach throwing a frisbee while two people walking the water <end>\n",
            "<start> a man standing on top of a beach near a yellow umbrella <end>\n",
            "<start> a group of people are by the water on the beach playing frisbe <end>\n",
            "<start> a man jumps to catch a frisbee as a couple wades by on the beach <end>\n",
            "Predicted Caption: a man men light a one <end>\n",
            "BLEU Score: 0.236379\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133688.jpg\n",
            "Real Caption: <start> an old boxcar sits at a train museum <end>\n",
            "<start> an old fashioned passenger train is displayed at a museum <end>\n",
            "<start> a train in an antique musium green and vintage <end>\n",
            "<start> a green train car sitting on display inside of a building <end>\n",
            "<start> a black train car in a museum exhibition <end>\n",
            "Predicted Caption: a tie bench bench person's at a dressed <end>\n",
            "BLEU Score: 0.350373\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133722.jpg\n",
            "Real Caption: <start> a woman takes a bite of a large slice of pizza <end>\n",
            "<start> a beautiful young lady eating a slice of pizza <end>\n",
            "<start> a woman eating a large cheese pizza on a plate <end>\n",
            "<start> woman eating pizza during a night on the town <end>\n",
            "<start> a woman eating a slice of white pizza outside on the sidewalk <end>\n",
            "Predicted Caption: a man sits a around <end>\n",
            "BLEU Score: 0.422088\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133727.jpg\n",
            "Real Caption: <start> a professional baseball player warming up before going to bat <end>\n",
            "<start> the man is hitting the baseball during the game <end>\n",
            "<start> a baseball player holding a bat in a field <end>\n",
            "<start> a player holding a bat on a baseball field <end>\n",
            "<start> a baseball player practices his swing before going to bat <end>\n",
            "Predicted Caption: a air being a ski up a ski baby street ski baby street ski next to street ski baby street ski up the females middle\n",
            "BLEU Score: 0.624410\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133730.jpg\n",
            "Real Caption: <start> a baseball player signs autographs for several men <end>\n",
            "<start> a man in a baseball uniform signing autographs for people <end>\n",
            "<start> a baseball player signing a paper for a fan on a field <end>\n",
            "<start> there is a baseball player that is signing different fans noted <end>\n",
            "<start> a baseball player is giving his autograph to a man in a crowd <end>\n",
            "Predicted Caption: a his of people that horse train over people <end>\n",
            "BLEU Score: 0.739060\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000133739.jpg\n",
            "Real Caption: <start> black and white image of people doing exercises on surfboards <end>\n",
            "<start> ladies are exercising on rafts in the water <end>\n",
            "<start> a group of people riding surfboards while doing hand stands <end>\n",
            "<start> people do yoga on surfboards on the ocean <end>\n",
            "<start> some people in the water on surfboards are lifting their legs in the air <end>\n",
            "Predicted Caption: a chin rowboats skate of a frisbee and a skate of a frisbee and some skate of a man two a frisbee and frisbee and\n",
            "BLEU Score: 0.546210\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000264567.jpg\n",
            "Real Caption: <start> a group of police officers riding horses down a dirt road <end>\n",
            "<start> a number of people riding horses with people in stands <end>\n",
            "<start> cops are riding horses while in the parade <end>\n",
            "<start> group of officers in uniform riding horses in front of a crowd <end>\n",
            "<start> a crowd watching policemen riding horses in a show <end>\n",
            "Predicted Caption: a sitting group a bicycle bed resting a bicycle bed in a bicycle bed black a bicycle bed in a bed and a bed with\n",
            "BLEU Score: 0.218776\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000264589.jpg\n",
            "Real Caption: <start> a series of photos of a man doing a trick on a skateboard <end>\n",
            "<start> there is a montage of photos of a person riding a skateboard <end>\n",
            "<start> a collage of various photos of skateboarders doing tricks and riding skateboards <end>\n",
            "<start> a series of images of skateboarders skating and jumping <end>\n",
            "<start> several different examples of a skateboarder performing tricks <end>\n",
            "Predicted Caption: a skateboarder of by on a room <end>\n",
            "BLEU Score: 0.566367\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000264591.jpg\n",
            "Real Caption: <start> a man does a trick on his skateboard <end>\n",
            "<start> a man doing an ollie on a skateboard ramp <end>\n",
            "<start> a person jumping a skate board in the air <end>\n",
            "<start> a skate boarder in a concrete park in mid air <end>\n",
            "<start> a skateboarder flying up in the air along the edge of a ramp <end>\n",
            "Predicted Caption: a sitting is caption street while several in the baseball of a while several on a smiles day <end>\n",
            "BLEU Score: 0.378452\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000264598.jpg\n",
            "Real Caption: <start> a little boy walking along a pond with his father <end>\n",
            "<start> a child carefully walking along the edge of a pool with the assistance of an adult <end>\n",
            "<start> a photo of a little boy walking on the side of a pond <end>\n",
            "<start> a young boy is standing on the edge of a pond <end>\n",
            "<start> a little boy in a hat is on the edge of a pond <end>\n",
            "Predicted Caption: a man play stand a while blurry street while <end>\n",
            "BLEU Score: 0.587949\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000264608.jpg\n",
            "Real Caption: <start> a woman striking a pose with tennis gear <end>\n",
            "<start> a woman standing in front of a fence smiling and holding a tennis racket <end>\n",
            "<start> a lady standing by a building holding a tennis racket <end>\n",
            "<start> a woman is posing for a picture with a tennis racket <end>\n",
            "<start> a women holding a racket next to a wooden fence <end>\n",
            "Predicted Caption: a double catching from <end>\n",
            "BLEU Score: 0.322673\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000264636.jpg\n",
            "Real Caption: <start> many people riding surf boards with paddles in a body of water <end>\n",
            "<start> six people on standing surfboards paddling near cliffs <end>\n",
            "<start> a group of people riding paddle boats on top of blue water <end>\n",
            "<start> a group of people are using paddles to navigate their surfboards <end>\n",
            "<start> a group of people on surfboards in the water <end>\n",
            "Predicted Caption: a his of a drinks next to a costume people an dog front arms dog a piece of a as umbrella board at a large\n",
            "BLEU Score: 0.587949\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000264642.jpg\n",
            "Real Caption: <start> a man in a park trying to catch a frisbee <end>\n",
            "<start> a man is running to try and catch a frisbee <end>\n",
            "<start> a man trying to catch a frisbee on a green grass field <end>\n",
            "<start> a guy wearing red shorts playing frisbee on a grassy field <end>\n",
            "<start> man running and trying to catch a frisbee <end>\n",
            "Predicted Caption: a it are house rain a field in the adults snow horses feet <end>\n",
            "BLEU Score: 0.661390\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000264645.jpg\n",
            "Real Caption: <start> bruce campbell smiles as he walks by people <end>\n",
            "<start> a man waving and greeting a group at a casino <end>\n",
            "<start> group of people all standing around a open store <end>\n",
            "<start> having a hard time seeing what these people are doing because the picture is blurry <end>\n",
            "<start> a man standing in a crowd of people <end>\n",
            "Predicted Caption: a man black tall at a body <end>\n",
            "BLEU Score: 0.526160\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000264647.jpg\n",
            "Real Caption: <start> a man sitting next to a fan and a man holding a nintendo wii game controller <end>\n",
            "<start> a man standing is holding a wii controller near a fan <end>\n",
            "<start> one is man is standing while the other sits in their bare apartment <end>\n",
            "<start> two men in a room holding a remote control <end>\n",
            "<start> two young men are playing the wii system <end>\n",
            "Predicted Caption: a man is area in a couch around <end>\n",
            "BLEU Score: 0.595923\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000264708.jpg\n",
            "Real Caption: <start> a person holding a kitten that is licking on wood <end>\n",
            "<start> a small cat on someone's lap looking at a chair <end>\n",
            "<start> a kitten with his mouth on the bottom of a chair <end>\n",
            "<start> a kitten peeking around the leg of a chair <end>\n",
            "<start> a small cat smelling an old chair leg <end>\n",
            "Predicted Caption: a this of a friends <end>\n",
            "BLEU Score: 0.335147\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000264709.jpg\n",
            "Real Caption: <start> a white tray sitting on top of a table with a can of soda <end>\n",
            "<start> a big green table with some food and drink on it <end>\n",
            "<start> someone is eating a tv dinner and pop in an asian country <end>\n",
            "<start> a close up of a tray of food on a table <end>\n",
            "<start> a meal with a lunchbox and a banana <end>\n",
            "Predicted Caption: watching sits near a one of motorcycle <end>\n",
            "BLEU Score: 0.632878\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000264712.jpg\n",
            "Real Caption: <start> bowls of meats soups vegetables and rice served with chop sticks <end>\n",
            "<start> an assortment of asian foods are arranged on a wooden table <end>\n",
            "<start> plates of food consisting of different meats and some rice <end>\n",
            "<start> bowls of rice and soup and plates of meat take up most of the table space <end>\n",
            "<start> plates of meat rice vegetables and soup on a table <end>\n",
            "Predicted Caption: standing older people are cell city drinking <end>\n",
            "BLEU Score: 0.392109\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000264723.jpg\n",
            "Real Caption: <start> a horse and buddy come down the side of a road <end>\n",
            "<start> a man driving a racing buggy with a horse <end>\n",
            "<start> a man going down a road in a horse and buggy with a windmill in the background <end>\n",
            "<start> a man riding a horse drawn wagon along side of a field <end>\n",
            "<start> a horse pulling a buggy in the middle of the street <end>\n",
            "Predicted Caption: a their of a small mirror are elephant a together friends <end>\n",
            "BLEU Score: 0.315421\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000264734.jpg\n",
            "Real Caption: <start> a skater looks ahead as he rides down a ramp <end>\n",
            "<start> a boy is skateboarding down a ramp in a skate park <end>\n",
            "<start> a person riding a skate board at a skate park <end>\n",
            "<start> there is a male skateboarder going down a ramp <end>\n",
            "<start> a person on a skateboard rides down a ramp <end>\n",
            "Predicted Caption: a background at a several a ground a background green a man roll down the ball rail a shirt school on a while <end>\n",
            "BLEU Score: 0.282677\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000264741.jpg\n",
            "Real Caption: <start> several people sitting around together eating and drinking at a venue <end>\n",
            "<start> blurry photograph of travelers enjoying a beer together <end>\n",
            "<start> two men sit together as they have a drink <end>\n",
            "<start> people siting on a couch with a table full of food <end>\n",
            "<start> a couple of men sitting on a couch together in front of a table <end>\n",
            "Predicted Caption: or are haircut a flies winter who motorcycle sit of very <end>\n",
            "BLEU Score: 0.632878\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000264752.jpg\n",
            "Real Caption: <start> a man riding a surfboard on top of a crystal blue wave <end>\n",
            "<start> a male surfer is riding a large wave <end>\n",
            "<start> a man pops above the turquoise colored water and through a clear wave <end>\n",
            "<start> man catches awesome blue wave on his surfboard <end>\n",
            "<start> a man rides a surfboard on a blue wave of water <end>\n",
            "Predicted Caption: a man is group on a cake <end>\n",
            "BLEU Score: 0.566367\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000264758.jpg\n",
            "Real Caption: <start> a person walking on skies in the snow <end>\n",
            "<start> a man skiing in circles around in the snow <end>\n",
            "<start> the man in a black jacket is skiing in deep snow <end>\n",
            "<start> a man on skis goes through the snow <end>\n",
            "<start> a man snowshoeing across a snow covered town square <end>\n",
            "Predicted Caption: a sitting an on a table out laptop <end>\n",
            "BLEU Score: 0.695905\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000264781.jpg\n",
            "Real Caption: <start> two men playing frisbee with a photoshopped background <end>\n",
            "<start> two men playing frisbee photo shopped onto a grey background <end>\n",
            "<start> two men standing in mid air wearing sports uniforms with one man reaching for a red frisbee <end>\n",
            "<start> the two men are trying to play frisbee together <end>\n",
            "<start> two people playing frisbee with an artificial background <end>\n",
            "Predicted Caption: a man in it's ball traveling has a center has a while green a several <end>\n",
            "BLEU Score: 0.540688\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000264804.jpg\n",
            "Real Caption: <start> a black and white horse standing next to a crowd of people <end>\n",
            "<start> the horse is regally outfitted with a special bridle and headpiece <end>\n",
            "<start> a horse is wearing a red feather on its head <end>\n",
            "<start> the head of the black and white horse has a red decoration <end>\n",
            "<start> the show horse poses for photos before its performance <end>\n",
            "Predicted Caption: a bicycle bed and some bed in a bicycle bed in a bicycle bed in a bicycle skiers in a keyboard <end>\n",
            "BLEU Score: 0.518144\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000395673.jpg\n",
            "Real Caption: <start> bunch of people gathered around in the park holding frisbees <end>\n",
            "<start> several people standing at a park on a clear day <end>\n",
            "<start> group of people holding orange and blue frisbees <end>\n",
            "<start> a group of people outside looking at something <end>\n",
            "<start> a group of people watching a man give a demonstration <end>\n",
            "Predicted Caption: a sitting rain a covered <end>\n",
            "BLEU Score: 0.498638\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000395716.jpg\n",
            "Real Caption: <start> snow board sitting in snow with lots of people in background <end>\n",
            "<start> these snowboards are on the slope of a mountain <end>\n",
            "<start> snowboarders hanging out at the bottom of a snowy mountain <end>\n",
            "<start> snowboarders snowboarding down a huge snow covered mountain <end>\n",
            "<start> several people on snowboards hanging out in the snow <end>\n",
            "Predicted Caption: a cutting mountains down a table laptop next to a each in the table <end>\n",
            "BLEU Score: 0.340163\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000395718.jpg\n",
            "Real Caption: <start> a chef wearing an apron smiling holding a pizza in his hands <end>\n",
            "<start> a man holding a huge pizza smiling for a photo shoot <end>\n",
            "<start> a man holds an oblong pizza over a wood table as he smokes for the camera <end>\n",
            "<start> man with apron holding a pizza in the shape of a shoe <end>\n",
            "<start> a man holding a long piece of bread with melted cheese on it <end>\n",
            "Predicted Caption: a food is pedestrians a glass in skateboard of food with a food is lays towards person in skateboard of food <end>\n",
            "BLEU Score: 0.651314\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000395740.jpg\n",
            "Real Caption: <start> a group of benches sitting outside of a building at night <end>\n",
            "<start> individuals are doing something right now that is riveting \n",
            " <end>\n",
            "<start> some people are eating outdoors at a cafe at night <end>\n",
            "<start> several patio tables are lit up outside of the building <end>\n",
            "<start> a small outdoor group of tables on the corner of a city street <end>\n",
            "Predicted Caption: a man cat in skateboard of bus <end>\n",
            "BLEU Score: 0.558513\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000395742.jpg\n",
            "Real Caption: <start> two girls playing soccer while the rest of the team watches <end>\n",
            "<start> the cover of a media guide depicts female soccer players <end>\n",
            "<start> two female soccer players going against each other <end>\n",
            "<start> a couple of girls are playing a soccer game <end>\n",
            "<start> two women in different teams running for a soccer ball during a game <end>\n",
            "Predicted Caption: a his of people house with a water <end>\n",
            "BLEU Score: 0.695905\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000395766.jpg\n",
            "Real Caption: <start> a kid and a couple of women around a table <end>\n",
            "<start> four people gathered around a table that has a cake sitting on it <end>\n",
            "<start> a group of ladies around a table with a cake and table cloth on it <end>\n",
            "<start> people outside with a birthday cake and plates <end>\n",
            "<start> a group of people that appear to be family setting a table <end>\n",
            "Predicted Caption: a man and a upside at a large playing flying on the baseball of runway married and racing at a skiers up runway married <end>\n",
            "BLEU Score: 0.218776\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000395768.jpg\n",
            "Real Caption: <start> a man in a white uniform holds a bat with two other men on a baseball field <end>\n",
            "<start> a baseball player ready to hit a pitch with a catcher and umpire behind him <end>\n",
            "<start> a baseball player is holding a bat above his head <end>\n",
            "<start> a person up to bat and a baseball game <end>\n",
            "<start> a baseball game in progress with the batter up to plate <end>\n",
            "Predicted Caption: a air her is skateboarding a child <end>\n",
            "BLEU Score: 0.638474\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000395817.jpg\n",
            "Real Caption: <start> a man is laying in bed with a very tiny baby <end>\n",
            "<start> a man that is laying next to a little baby <end>\n",
            "<start> an older man and a baby laying together on a bed <end>\n",
            "<start> an older man lies in bed with a very young baby <end>\n",
            "<start> an old man laying in a bed with his hands wrapped around a baby <end>\n",
            "Predicted Caption: a bat with street walking eating on top bat with a walking bat with a trick <end>\n",
            "BLEU Score: 0.248469\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000395828.jpg\n",
            "Real Caption: <start> a train with a red caboose sitting on tracks <end>\n",
            "<start> a train car sits parked as people stand next to it <end>\n",
            "<start> an old fashion train sits on the tracks at a station <end>\n",
            "<start> there is a red cabose on the train tracks <end>\n",
            "<start> a train driving down the train tracks out side <end>\n",
            "Predicted Caption: grafitti racket wave the bench lap at fork a dressed being a bench lap person at the can buggy paper person dog hut lap <end>\n",
            "BLEU Score: 0.546210\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000395830.jpg\n",
            "Real Caption: <start> a young child carrying luggage through an airport <end>\n",
            "<start> a small boy in a ball cap is pulling luggage by a handle <end>\n",
            "<start> young boy in summer clothes and a baseball cap with wheeled hand luggage <end>\n",
            "<start> a young child drags carry on luggage in a parking lot <end>\n",
            "<start> a small child in a hat rolling his own suitcase <end>\n",
            "Predicted Caption: a man that is traveling racket the pants long <end>\n",
            "BLEU Score: 0.587949\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000395840.jpg\n",
            "Real Caption: <start> a person holding a phone in their right hand <end>\n",
            "<start> they are trying to look at their phone in the dark <end>\n",
            "<start> cell phone in the dark displaying an image <end>\n",
            "<start> someone holding up a mobile phone while playing a game <end>\n",
            "<start> in the dark a cell phone is glowing blue and green <end>\n",
            "Predicted Caption: a man jumping a three of a old game at the old game <end>\n",
            "BLEU Score: 0.711931\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000395850.jpg\n",
            "Real Caption: <start> a jet flying through the clear blue sky <end>\n",
            "<start> a large air force jet flying through he blue sky on it's side <end>\n",
            "<start> a jet fighter plane making a steep bank <end>\n",
            "<start> that is an extremely odd airplane flying across the blue sky <end>\n",
            "<start> a large military jet flying side ways in the air <end>\n",
            "Predicted Caption: a equipment <end>\n",
            "BLEU Score: 0.131439\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000395851.jpg\n",
            "Real Caption: <start> a woman laughing and messing with a blender <end>\n",
            "<start> a person operating an electric blender on a counter <end>\n",
            "<start> black and white photograph of woman using a blender <end>\n",
            "<start> a person holding onto a blender while it is blending <end>\n",
            "<start> black and white photograph of a happy woman making a smoothie <end>\n",
            "Predicted Caption: a woman is two a be of motorcycle <end>\n",
            "BLEU Score: 0.414706\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000395853.jpg\n",
            "Real Caption: <start> a group of people stand together near a cake <end>\n",
            "<start> a group of people standing by a table with a cake <end>\n",
            "<start> a group of people in business suits stand around and smile <end>\n",
            "<start> seven people posing for a group picture in business clothing <end>\n",
            "<start> six women and one man are posing for a picture <end>\n",
            "Predicted Caption: a his of people with top <end>\n",
            "BLEU Score: 0.345878\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000395863.jpg\n",
            "Real Caption: <start> a boy having lunch at an asian restaurant <end>\n",
            "<start> a variety of foods on a table at a busy restaurant <end>\n",
            "<start> a variety of different foods are on the table for your choosing <end>\n",
            "<start> a boy and his family enjoys a meal in a restaurant <end>\n",
            "<start> sitting at a large table in a restaurant eating with chopsticks <end>\n",
            "Predicted Caption: a his of people step flock and buses up a playing cellphone with motorcycle hot of motorcycle <end>\n",
            "BLEU Score: 0.695905\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000395888.jpg\n",
            "Real Caption: <start> a women who is shredding a carrot in a bowl <end>\n",
            "<start> a woman standing at the counter grating carrots <end>\n",
            "<start> a woman standing by a sink with carrots on the counter <end>\n",
            "Predicted Caption: a it cow near in the kitchen kitchen <end>\n",
            "BLEU Score: 0.695905\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000526713.jpg\n",
            "Real Caption: <start> three giraffes in the jungle with people on horse back <end>\n",
            "<start> several giraffes with people on horses in the background <end>\n",
            "<start> a herd of giraffe being watched a group on horseback <end>\n",
            "<start> giraffes are herded by a group of people on horses <end>\n",
            "<start> three giraffes in field with three people on horseback in the background <end>\n",
            "Predicted Caption: a woman and laying are soccer a race <end>\n",
            "BLEU Score: 0.695905\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000526729.jpg\n",
            "Real Caption: <start> there are a lot of people that are on the ski slope <end>\n",
            "<start> a group of people skiing down a snow covered slope <end>\n",
            "<start> a lot of people are snow boarding in winter olympics <end>\n",
            "<start> a group of cross county skiers on a course <end>\n",
            "<start> a bunch of skiers with the same team uniforms seem to be waiting in line <end>\n",
            "Predicted Caption: people an next to a walks books of a small car <end>\n",
            "BLEU Score: 0.749084\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000526734.jpg\n",
            "Real Caption: <start> a man sitting at a desk in front of a computer <end>\n",
            "<start> a person sitting at a desk with a monitor and keyboard <end>\n",
            "<start> a person sitting at a desk with a computer <end>\n",
            "<start> a man is staring intently at what is on the computer screen <end>\n",
            "<start> a man sitting in front of a desktop computer <end>\n",
            "Predicted Caption: a traffic near of a across flipping <end>\n",
            "BLEU Score: 0.335940\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000526750.jpg\n",
            "Real Caption: <start> a man flipping upside down in the air while riding a scooter <end>\n",
            "<start> a man on a scooter doing a trick in the air <end>\n",
            "<start> a man performing a flip trick on a scooter <end>\n",
            "<start> man on a scooter upside down under a bright blue sky <end>\n",
            "<start> a person performing a trick on a scooter <end>\n",
            "Predicted Caption: a man red a field <end>\n",
            "BLEU Score: 0.335147\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000526769.jpg\n",
            "Real Caption: <start> a man riding on the back of a motorcycle wearing a jacket and tie <end>\n",
            "<start> a man in a business suit and a motorcycle helmet riding a motorcycle <end>\n",
            "<start> a man in a suit on a motorcycle in front of the bus <end>\n",
            "<start> a man dressed in a suit is riding a motorcycle <end>\n",
            "<start> a dressed up man riding an expensive motorcycle to work <end>\n",
            "Predicted Caption: a man on a can <end>\n",
            "BLEU Score: 0.331925\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000526810.jpg\n",
            "Real Caption: <start> an image of man holding two cellphone to his ears <end>\n",
            "<start> a man is holding a cell phone to each of his ears <end>\n",
            "<start> a smiling man putting headphones on his ears <end>\n",
            "<start> a man talking on a cell phone while wearing a watch <end>\n",
            "<start> smiling man holds two phones up to his ears <end>\n",
            "Predicted Caption: a traffic near standing hillside <end>\n",
            "BLEU Score: 0.396685\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000526825.jpg\n",
            "Real Caption: <start> a group of men riding on the back of a boat <end>\n",
            "<start> people are riding in a motorized raft in the water <end>\n",
            "<start> a boat with people is cruising in a bay <end>\n",
            "<start> a speedboat with an american flag coming up to big city <end>\n",
            "<start> a boat with people and a flag on it is in the water near a city <end>\n",
            "Predicted Caption: a sitting on a holds on scissors side of the book <end>\n",
            "BLEU Score: 0.749084\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000526856.jpg\n",
            "Real Caption: <start> a person in a red coat skiing in the snow <end>\n",
            "<start> a man is gliding his snowboard down the mountain <end>\n",
            "<start> a man riding skis down the side of a ski slope <end>\n",
            "<start> a man who is skiing down a snowy hill <end>\n",
            "<start> a man is turned so that he is almost on his knees while skiing downhill <end>\n",
            "Predicted Caption: people are an in the bank of table <end>\n",
            "BLEU Score: 0.350373\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000526861.jpg\n",
            "Real Caption: <start> a train drives down a track next to the ocean <end>\n",
            "<start> a transit vehicle on track with water in the background <end>\n",
            "<start> a train is approaching alongside a body of water <end>\n",
            "<start> a blue train traveling over a bridge over a large body of water <end>\n",
            "<start> a blue train going over a wooden bridge <end>\n",
            "Predicted Caption: a forest smiling of a can dog the can suitcase <end>\n",
            "BLEU Score: 0.716177\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000526867.jpg\n",
            "Real Caption: <start> a man squatting and holding a basketball by one hand <end>\n",
            "<start> man squatting down on a paved surface with his right hand on top of a basketball <end>\n",
            "<start> a man is resting with a basketball on a court <end>\n",
            "<start> a man is squatting with a basketball in his hand <end>\n",
            "<start> a man is outside crouching by a basketball <end>\n",
            "Predicted Caption: bottle taking in hand <end>\n",
            "BLEU Score: 0.405605\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000526877.jpg\n",
            "Real Caption: <start> row of motorcycles next to a city street and sidewalk with pedestrians <end>\n",
            "<start> a row of motorcycles parked in front of tall brick buildings <end>\n",
            "<start> long lines of motorcycles parked along boths sides of the road <end>\n",
            "<start> pedestrians passing a long line of motorcycles on a city street <end>\n",
            "<start> a street lined with parked motorcycles on both sides <end>\n",
            "Predicted Caption: a room attire <end>\n",
            "BLEU Score: 0.181323\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000526881.jpg\n",
            "Real Caption: <start> a bicycler riding in the bike lane down a street <end>\n",
            "<start> a person riding a bicycle on a bicycle street lane <end>\n",
            "<start> a cyclist riding in the bicycle lane of a city street <end>\n",
            "<start> a man rides a bicycle in the bike lane in the winter <end>\n",
            "<start> a person riding a bike in the bicycles only lane <end>\n",
            "Predicted Caption: a sitting wooden horse getting <end>\n",
            "BLEU Score: 0.284237\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000526887.jpg\n",
            "Real Caption: <start> the person stands on the surfboard on a small wave <end>\n",
            "<start> a person surfing on top of the water <end>\n",
            "<start> a surfer rides a small wave in a vast body of water <end>\n",
            "<start> a man paddle boarding in the calm ocean <end>\n",
            "<start> a person rides a surfboard on quiet waters <end>\n",
            "Predicted Caption: a frisbee and frisbee guitars is baby the wearing <end>\n",
            "BLEU Score: 0.587949\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000526912.jpg\n",
            "Real Caption: <start> a group of men standing around parked motorcycles <end>\n",
            "<start> some men are standing outside with their motorcycles <end>\n",
            "<start> the friends are standing around their motor bikes <end>\n",
            "<start> a bunch of people that are near motorcycles <end>\n",
            "<start> three helmeted motorcyclists are standing near their bikes <end>\n",
            "Predicted Caption: a woman and it person down a frisbee scooter court next to court court dog a room court next to over people <end>\n",
            "BLEU Score: 0.446652\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000526922.jpg\n",
            "Real Caption: <start> view of multiple buses and a truck in traffic <end>\n",
            "<start> a number of public transit buses in traffic <end>\n",
            "<start> buses and trucks crowded together in tight traffic <end>\n",
            "<start> many buses are scattered together in a traffic jam <end>\n",
            "<start> there are buses and other vehicles moving down a crowded street <end>\n",
            "Predicted Caption: shoes <end>\n",
            "BLEU Score: 0.000000\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000526953.jpg\n",
            "Real Caption: <start> a man jumping up into the air holding a tennis racquet <end>\n",
            "<start> a guy returns the ball during a tennis match <end>\n",
            "<start> a male tennis player in a black shirt playing tennis <end>\n",
            "<start> a tennis player jumping in the air after returning a serve <end>\n",
            "<start> a man jumping in the air and swinging his racket while playing tennis <end>\n",
            "Predicted Caption: a man white a tennis plate teddy resting the surface parked with double umbrella is elephants to ground the parked with a tennis parked <end>\n",
            "BLEU Score: 0.275005\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000526957.jpg\n",
            "Real Caption: <start> a group of people with surfing boards on a shoreline <end>\n",
            "<start> an line of people stand in front of their propped upright surfboards <end>\n",
            "<start> a group of surfers at the beach posing with their boards <end>\n",
            "<start> a group of people that are standing in front of a surfboard <end>\n",
            "<start> a group of men standing next to each other near a row of surf boards <end>\n",
            "Predicted Caption: the people an up a picture <end>\n",
            "BLEU Score: 0.541591\n",
            "\n",
            "\n",
            "http://images.cocodataset.org/train2014/COCO_train2014_000000526958.jpg\n",
            "Real Caption: <start> a plane sitting on a runway during the day <end>\n",
            "<start> a white plane that is sitting on the concrete <end>\n",
            "<start> a small personal plane parked on a runway <end>\n",
            "<start> a person sitting on the ground while watching a plane on the runway <end>\n",
            "<start> a small propeller plane getting ready to take off from an airport <end>\n",
            "Predicted Caption: paper kid in the earth in standing driving in a frisbee planes an at standing planes pulling in the octopus of monochrome dogs octopus of\n",
            "BLEU Score: 0.546210\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ32NTg71PgD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "c60d770e-b5d6-4e43-f161-a3d274635633"
      },
      "source": [
        "\n",
        "url = ['https://www.flickr.com/photos/95607642@N04/30227592486/']\n",
        "testimage_url=[]\n",
        "test_pred_cap=[]       \n",
        "for url in url:\n",
        "  name=os.path.basename(url)\n",
        "  print(name)\n",
        "  image_path= tf.keras.utils.get_file(name,origin=url)\n",
        "  result, attention_plot_1 = evaluate(image_path)\n",
        "  print(\"Image Url:\", url)\n",
        "  print ('Predicted Caption:', ' '.join(result))\n",
        "  print(\"\\n\")\n",
        "  plot_attention(image_path, result, attention_plot_1)\n",
        "  pred_cap= ' '.join(result)\n",
        "  testimage_url.append(url)\n",
        "  test_pred_cap.append(pred_cap)\n",
        "testdata = pd.DataFrame({ \"Image_url\" : testimage_url,\"Predicted Captions\": test_pred_cap })\n",
        "testdata=testdata.sort_values(by=['Image_url', 'Predicted Captions'])\n",
        "testdata.to_csv(\"/content/gdrive/My Drive/Colab Notebooks/testdata.csv\", index=False)\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-afb46203e556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mimage_path\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_plot_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image Url:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted Caption:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-8dbe5fb0edd6>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtemp_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mimg_tensor_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_features_extract_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mimg_tensor_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_tensor_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_tensor_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_tensor_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-862c73d29b96>\u001b[0m in \u001b[0;36mload_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_jpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m299\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minception_v3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m       return read_file_eager_fallback(\n\u001b[0;32m--> 562\u001b[0;31m           filename, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m    563\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mread_file_eager_fallback\u001b[0;34m(filename, name, ctx)\u001b[0m\n\u001b[1;32m    598\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m   _result = _execute.execute(b\"ReadFile\", 1, inputs=_inputs_flat,\n\u001b[0;32m--> 600\u001b[0;31m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m    601\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m     _execute.record_gradient(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: /root/.keras/datasets; Is a directory [Op:ReadFile]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8U6r1HjpBkB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "outputId": "b7eeb843-e5e2-45cd-a7ec-47486e6a9083"
      },
      "source": [
        "image_url = ['/content/gdrive/My Drive/Colab Notebooks/test_images/test_image1.jpg',\n",
        "'/content/gdrive/My Drive/Colab Notebooks/test_images/test_image2.jpg',\n",
        "'/content/gdrive/My Drive/Colab Notebooks/test_images/test_image3.jpg',\n",
        "'/content/gdrive/My Drive/Colab Notebooks/test_images/test_image4.jpg',\n",
        "'/content/gdrive/My Drive/Colab Notebooks/test_images/test_image5.jpg',\n",
        "'/content/gdrive/My Drive/Colab Notebooks/test_images/test_image6.jpg',\n",
        "'/content/gdrive/My Drive/Colab Notebooks/test_images/test_image6.jpg',\n",
        "'/content/gdrive/My Drive/Colab Notebooks/test_images/test_image7.jpg',\n",
        "'/content/gdrive/My Drive/Colab Notebooks/test_images/test_image8.jpg',\n",
        "'/content/gdrive/My Drive/Colab Notebooks/test_images/test_image9.jpg',\n",
        "'/content/gdrive/My Drive/Colab Notebooks/test_images/test_image10.jpg']\n",
        "             \n",
        "testimage_url=[]\n",
        "test_pred_cap=[]       \n",
        "for url in image_url:\n",
        "  result, attention_plot_1 = evaluate(url)\n",
        "  print(\"Image Url:\", url)\n",
        "  print ('Predicted Caption:', ' '.join(result))\n",
        "  print(\"\\n\")\n",
        "  #plot_attention(image_path, result, attention_plot_1)\n",
        "  pred_cap= ' '.join(result)\n",
        "  testimage_url.append(url)\n",
        "  test_pred_cap.append(pred_cap)\n",
        "testdata = pd.DataFrame({ \"Image_url\" : testimage_url,\"Predicted Captions\": test_pred_cap })\n",
        "testdata=testdata.sort_values(by=['Image_url', 'Predicted Captions'])\n",
        "testdata.to_csv(\"/content/gdrive/My Drive/Colab Notebooks/testdata.csv\", index=False)\n",
        "\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image Url: /content/gdrive/My Drive/Colab Notebooks/test_images/test_image1.jpg\n",
            "Predicted Caption: a laying market in the sidewalk next to a large piece of top sign in a player of a sign <end>\n",
            "\n",
            "\n",
            "Image Url: /content/gdrive/My Drive/Colab Notebooks/test_images/test_image2.jpg\n",
            "Predicted Caption: a man person on a colorful <end>\n",
            "\n",
            "\n",
            "Image Url: /content/gdrive/My Drive/Colab Notebooks/test_images/test_image3.jpg\n",
            "Predicted Caption: a large his of bunch on a loud <end>\n",
            "\n",
            "\n",
            "Image Url: /content/gdrive/My Drive/Colab Notebooks/test_images/test_image4.jpg\n",
            "Predicted Caption: a sitting racket to horses frisbee colorful <end>\n",
            "\n",
            "\n",
            "Image Url: /content/gdrive/My Drive/Colab Notebooks/test_images/test_image5.jpg\n",
            "Predicted Caption: a background umbrellas down a while <end>\n",
            "\n",
            "\n",
            "Image Url: /content/gdrive/My Drive/Colab Notebooks/test_images/test_image6.jpg\n",
            "Predicted Caption: a beach that is board down the brown of a bagel building <end>\n",
            "\n",
            "\n",
            "Image Url: /content/gdrive/My Drive/Colab Notebooks/test_images/test_image6.jpg\n",
            "Predicted Caption: a beach is an on a bat next to a drinking <end>\n",
            "\n",
            "\n",
            "Image Url: /content/gdrive/My Drive/Colab Notebooks/test_images/test_image7.jpg\n",
            "Predicted Caption: a fixes and a sitting family a high of a work of motorcycle in a kitchen who a drinking <end>\n",
            "\n",
            "\n",
            "Image Url: /content/gdrive/My Drive/Colab Notebooks/test_images/test_image8.jpg\n",
            "Predicted Caption: a trick in a couch around <end>\n",
            "\n",
            "\n",
            "Image Url: /content/gdrive/My Drive/Colab Notebooks/test_images/test_image9.jpg\n",
            "Predicted Caption: a large pitcher elephant a sled is person on a kitchen <end>\n",
            "\n",
            "\n",
            "Image Url: /content/gdrive/My Drive/Colab Notebooks/test_images/test_image10.jpg\n",
            "Predicted Caption: a man pedestrians the small walking skis bus <end>\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}